{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omo-Tines/Sentiment-Analysis-ML/blob/main/SENIMLLAB4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==0.8.0 torchtext==0.9.0\n",
        "#==1.11.0\n",
        "#==0.9.0\n",
        "\n",
        "# Reload environment\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0ONCeUPOvwI",
        "outputId": "77072a3d-4cbe-4d3d-a96d-0540ce28e579"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.8.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==0.8.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pQux0sN_bwtB"
      },
      "outputs": [],
      "source": [
        "#Creating the tokenizer and labels\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = torchtext.data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm',\n",
        "                  include_lengths = True)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kippus6-e2Jb"
      },
      "source": [
        "#Importing the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R4zT3RAOb2ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d77917ca-0000-4228-eeac-47d8fb335159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 11.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchtext import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2gAzbaMe5Ac"
      },
      "source": [
        "#Splitting the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LHi16rv1dTwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "940f00c6-cb9f-43af-cb4b-6daf17bae7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18750\n",
            "6250\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "train_data, valid_data = train_data.split(\n",
        "    split_ratio=[0.75, 0.25],\n",
        "    random_state=random.seed(SEED))\n",
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "98xdFxeosBxm"
      },
      "outputs": [],
      "source": [
        "test_data, other_data = test_data.split(\n",
        "    split_ratio=[0.75, 0.25],\n",
        "    random_state=random.seed(SEED))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fmOYHW2e-IR"
      },
      "source": [
        "#Building a vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0uOZh2_Wb4xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf9166a-635f-4711-c27a-4b8f0a2943c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:20<00:00, 19123.45it/s]\n"
          ]
        }
      ],
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data,\n",
        "                 max_size = MAX_VOCAB_SIZE,\n",
        "                 vectors = \"glove.6B.100d\",\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lp5knEZJb-iq"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)\n",
        "test_loader=train_iterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LZq5lmBIcC3d"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        self.rnn = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           dropout=dropout)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        #pack sequence\n",
        "        # lengths need to be on CPU!\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "\n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "\n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "\n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "\n",
        "        return self.fc(hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tmZNKVGVcuD2"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM,\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM,\n",
        "            OUTPUT_DIM,\n",
        "            N_LAYERS,\n",
        "            BIDIRECTIONAL,\n",
        "            DROPOUT,\n",
        "            PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wiGWuYRycxg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462e9d0f-8232-436b-f904-14c0684aaf52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 4,810,857 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cUuITT_Cde-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df70ddb4-ddb8-4e77-ca33-6c3f2c24be1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25002, 100])\n"
          ]
        }
      ],
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T7h2KPRGdiFu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a8e69d-c36f-47ad-d20f-1c250265c15a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [-0.1071,  0.6057,  0.6343,  ...,  0.3833,  0.6149,  0.4702],\n",
              "        [-1.0149,  1.9495, -1.0922,  ..., -0.8807, -0.4166, -0.8111],\n",
              "        [-1.0410, -0.0363,  1.5732,  ..., -0.9128,  0.9207, -2.4707]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Qr5e5betdnHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29809e6f-f046-4d60-aeb2-c2f6784c5c3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.1071,  0.6057,  0.6343,  ...,  0.3833,  0.6149,  0.4702],\n",
            "        [-1.0149,  1.9495, -1.0922,  ..., -0.8807, -0.4166, -0.8111],\n",
            "        [-1.0410, -0.0363,  1.5732,  ..., -0.9128,  0.9207, -2.4707]])\n"
          ]
        }
      ],
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "print(model.embedding.weight.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BDAlfykMdu9Y"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DLXu2kfPdxaB"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LoN-xejXdz_p"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "  \"\"\"\n",
        "  Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "  \"\"\"\n",
        "  #round predictions to the closest integer\n",
        "  rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = (rounded_preds == y).float() #convert into float for division\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3sItK5IleGj-"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, text_lengths = batch.text\n",
        "\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KN2sLBUveOIL"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            txt, text_lengths = batch.text\n",
        "\n",
        "            predictions = model(txt, text_lengths).squeeze(1)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TMVhMZ6iePrM"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elps_time = end_time - start_time\n",
        "    elps_mins = int(elps_time / 60)\n",
        "    elps_secs = int(elps_time - (elps_mins * 60))\n",
        "    return elps_mins, elps_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dGrzeTqE3DTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53345dd-50c5-41da-ee25-9df7a450b580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ],
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tw9MAD9Sex4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58124584-85f4-45df-bc64-49fb85a99689"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 34s\n",
            "\tTrain Loss: 0.651 | Train Acc: 60.89%\n",
            "\t Val. Loss: 0.673 |  Val. Acc: 58.99%\n",
            "Epoch: 02 | Epoch Time: 0m 35s\n",
            "\tTrain Loss: 0.636 | Train Acc: 63.45%\n",
            "\t Val. Loss: 0.572 |  Val. Acc: 71.19%\n",
            "Epoch: 03 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 0.540 | Train Acc: 72.76%\n",
            "\t Val. Loss: 0.372 |  Val. Acc: 84.66%\n",
            "Epoch: 04 | Epoch Time: 0m 38s\n",
            "\tTrain Loss: 0.475 | Train Acc: 78.18%\n",
            "\t Val. Loss: 0.538 |  Val. Acc: 74.70%\n",
            "Epoch: 05 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.369 | Train Acc: 84.26%\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 86.13%\n"
          ]
        }
      ],
      "source": [
        "numepo = 5\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(numepo):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    tr_loss, tr_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    val_loss, val_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    endt = time.time()\n",
        "\n",
        "    emins, esecs = epoch_time(start_time, endt)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_valid_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {emins}m {esecs}s')\n",
        "    print(f'\\tTrain Loss: {tr_loss:.3f} | Train Acc: {tr_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Q82RFBkifSHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71408c2e-c5b8-49cb-dc12-68d4795842fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.367 | Test Acc: 85.57%\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wioXBh71U1_j"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    index = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    lgth = [len(index)]\n",
        "    tensor = torch.LongTensor(index).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(lgth)\n",
        "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
        "    return prediction.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cWJU-JQqU4d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f286c7fa-a00f-482a-a8ab-392501631a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.020738571882247925"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is terrible\")\n",
        "#close to 0 is negative and close to 1 is positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "p06316iOXqTW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343d04df-fd75-4806-e3fa-a13744451639"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9962856769561768"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "predict_sentiment(model, \"This film is amazing\")\n",
        "#close to 0 is negative and close to 1 is positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "34i2cCnO-k-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "651bb60d-7a2d-41c8-f0e7-d1292cea5d0f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c0960c1d5749>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -Uqq fastbook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfastbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfastbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_book\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastbook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastbook/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0.0.29\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkgutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastdownload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdownload_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastai/vision/all.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastai/vision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxresnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fastai/vision/models/tvm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvnext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdensenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgooglenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/convnext.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStochasticDepth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_presets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgiou_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneralized_box_iou_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3dNormActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSqueezeExcitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpoolers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiScaleRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_align\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIAlign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mps_roi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mps_roi_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPSRoIPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/poolers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroi_align\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroi_align\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/roi_align.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mallowed_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlist_backends\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconvert_frame\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m from .decorators import (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/allowed_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeprecated_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbolic_trace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_fx_tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/deprecated.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mapis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_transforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_functional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_nn_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0min_dims_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margnums_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_functorch/apis.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#       and there isn't a mechanism to selectively expose only some functions (eg. grad) from a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#       to Dynamo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from torch._functorch.vmap import (vmap_impl, _check_randomness_arg,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                    \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_dims_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_out_dims_is_int_or_int_pytree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                    _process_batched_inputs, _chunked_vmap)\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'vmap_impl' from 'torch._functorch.vmap' (/usr/local/lib/python3.10/dist-packages/torch/_functorch/vmap.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#hide\n",
        "import torchtext\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.YELP_REVIEWS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oD4gisdMDVv"
      },
      "outputs": [],
      "source": [
        "#ylpdata= datasets.YelpReviewFull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "htZzuB_aFLp9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8d059d11-ef29-4895-ff59-a0a8223e67cc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-032626534834>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBASE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
          ]
        }
      ],
      "source": [
        "Path.BASE_PATH = path\n",
        "path.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahn4h3in7WJO"
      },
      "outputs": [],
      "source": [
        "\n",
        "YLPTEXT = torchtext.legacy.data.LabelField(dtype=torch.long)\n",
        "### Defining the label processing\n",
        "\n",
        "YLPLABEL = torchtext.legacy.data.Field(\n",
        "    tokenize='spacy', # default splits on whitespace\n",
        "    tokenizer_language='en_core_web_sm'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbIXHsZJ7ZR4"
      },
      "outputs": [],
      "source": [
        "fields = [('TEXT_COLUMN_NAME',YLPTEXT ), ('LABEL_COLUMN_NAME', YLPLABEL)]\n",
        "\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "    path=path/'test.csv', format='csv',\n",
        "    skip_header=True, fields=fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zyyPSUwGKGB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "ylptest_data, no_test = dataset.split(\n",
        "    split_ratio=[0.10, 0.90],\n",
        "    random_state=random.seed(SEED))\n",
        "\n",
        "print(f'Num Test: {len(ylptest_data)}')\n",
        "print(f'Num non Test: {len(no_test)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ol2Dxxyw6YRu"
      },
      "outputs": [],
      "source": [
        "# trdataset = torchtext.legacy.data.TabularDataset(\n",
        "#     path=path/'train.csv', format='csv',\n",
        "#     skip_header=True, fields=fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z_SdipL6e7m"
      },
      "outputs": [],
      "source": [
        "# trainylp_data, validylp_data = dataset.split(\n",
        "#     split_ratio=[0.8, 0.2],\n",
        "#     random_state=random.seed(SEED))\n",
        "\n",
        "# print(f'Num Train: {len(trainylp_data)}')\n",
        "# print(f'Num Valid: {len(validylp_data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLmY-H3hCMe2"
      },
      "outputs": [],
      "source": [
        "print(vars(ylptest_data.examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMfJHhID7Agh"
      },
      "outputs": [],
      "source": [
        "YLPLABEL.build_vocab(ylptest_data, max_size=MAX_VOCAB_SIZE)\n",
        "YLPTEXT.build_vocab(ylptest_data)\n",
        "\n",
        "print(f'Vocabulary size: {len(YLPLABEL.vocab)}')\n",
        "print(f'Number of classes: {len(YLPTEXT.vocab)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gZw1RvG8cn_"
      },
      "outputs": [],
      "source": [
        "print(YLPTEXT.vocab.stoi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNspIVlyPIun"
      },
      "outputs": [],
      "source": [
        "yelp_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tst_loader = \\\n",
        "    torchtext.legacy.data.BucketIterator(\n",
        "        ylptest_data,\n",
        "         batch_size=BATCH_SIZE,\n",
        "         sort_within_batch=False,\n",
        "         sort_key=lambda x: len(x.LABEL_TEXT_NAME),\n",
        "         device=yelp_device\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "or6HpIew94c4"
      },
      "outputs": [],
      "source": [
        "print('\\nTest:')\n",
        "for batch in test_loader:\n",
        "    print(f'Text matrix size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXtyaHK65opU"
      },
      "outputs": [],
      "source": [
        "for batch in test_loader:\n",
        "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
        "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnucO9TxI9DL"
      },
      "outputs": [],
      "source": [
        "#tloss, tacc=train(model, test_loader, optimizer, criterion)\n",
        "tloss, tacc = evaluate(model, test_loader, criterion)\n",
        "\n",
        "print(f'Test Loss: {tloss:.3f} | Test Acc: {tacc*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvaQcdIhMMyH"
      },
      "outputs": [],
      "source": [
        "path1 = untar_data(URLs.IMDB)\n",
        "Path.BASE_PATH = path1\n",
        "path1.ls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QhRzbOjJ0a1"
      },
      "outputs": [],
      "source": [
        "negl1=L()\n",
        "negl2=L()\n",
        "negl3=L()\n",
        "negl4=L()\n",
        "negl5=L()\n",
        "posl1=L()\n",
        "posl2=L()\n",
        "posl3=L()\n",
        "posl4=L()\n",
        "posl5=L()\n",
        "with open(path1/'test/neg/14_1.txt') as f:negl1 += L(*f.readlines())\n",
        "with open(path1/'test/neg/15_2.txt') as f:negl2+= L(*f.readlines())\n",
        "with open(path1/'test/neg/16_1.txt') as f:negl3+= L(*f.readlines())\n",
        "with open(path1/'test/neg/17_3.txt') as f:negl4+= L(*f.readlines())\n",
        "with open(path1/'test/neg/18_1.txt') as f:negl5+= L(*f.readlines())\n",
        "with open(path1/'test/pos/13_9.txt') as f:posl1 += L(*f.readlines())\n",
        "with open(path1/'test/pos/14_8.txt') as f:posl2+= L(*f.readlines())\n",
        "with open(path1/'test/pos/16_8.txt') as f:posl3+= L(*f.readlines())\n",
        "with open(path1/'test/pos/17_8.txt') as f:posl4+= L(*f.readlines())\n",
        "with open(path1/'test/pos/18_8.txt') as f:posl5+= L(*f.readlines())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3LzwjUYNTug"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(negl1)),negl1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BAk8HL0Oite"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(negl2)),negl2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4e8ses0OqF5"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(negl3)),negl3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQxcusFoOsz7"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(negl4)),negl4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lNgWncqO2de"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(negl5)),negl5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rj8rIoYdQaqP"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(posl1)),posl1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvGrrJo0RVr6"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(posl2)),posl2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YISZut_2RatN"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(posl3)),posl3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6QPKg1HRgLw"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(posl4)),posl4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3m-1im4RmX4"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(posl5)),posl5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niD_-78TT8Dk"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[0]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mamh13vHWLA1"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[1]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zrYwvQJWWXP"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[2]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruZFcxjzWYje"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[3]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F82ykYV-WcaS"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[4]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyrSxfRaWqfx"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[5]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqiiDhD2Ws1a"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[6]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUC0sbXeWvAN"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[7]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyA0bHPiWx5D"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[8]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTqia-erW1Ka"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[9]).values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dogz8arW3o3"
      },
      "outputs": [],
      "source": [
        "predict_sentiment(model,str(vars(ylptest_data.examples[10]).values()))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFix63xxqJ0fogOPxyeFM1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}